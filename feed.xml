<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://jtwiggs.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://jtwiggs.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-04-02T22:47:00+00:00</updated><id>https://jtwiggs.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Week 13 - Conference Week</title><link href="https://jtwiggs.github.io/blog/2025/Week13/" rel="alternate" type="text/html" title="Week 13 - Conference Week"/><published>2025-04-01T21:01:00+00:00</published><updated>2025-04-01T21:01:00+00:00</updated><id>https://jtwiggs.github.io/blog/2025/Week13</id><content type="html" xml:base="https://jtwiggs.github.io/blog/2025/Week13/"><![CDATA[<p>With a model working adequately as of Monday, I am super excited to say I have finally decided on what would be the most beneficial area to focus on with my presentation at this conference: How web crawling can bolster the usefulness of RAG models. I need to come up with a better title, one that is a bit more reflective of Crawl4AI’s impact on this project, and somehow tie in the UFC if possible. This went from creating a fun little tool to a much more research based idea. I feel that getting an RAG working with (technically) a single, relatively short, markdown file is already a win. I need to test it some more tomorrow, but the results I was getting looked very promising. I’m still mildly undecided on whether I cater towards the idea of an AI tool, or research specific presentation. Essentially, this semester of researching has lead to three key points that I want to get across in a professional way this week:</p> <p>While I built this workflow to collect information from the ufc homepage, some additional customization could make this collect information about almost any website, given the time to complete a full query. If the files are saved and managed effectively, a personal database of useful websites to use as text embeddings for the model can become extremely powerful. For example, crawling medicare.gov and connecting an RAG model to both a chatbot and a text-to-speech (tts) model would provide genuine value in answering plan specific questions immediately, and add an additional filter on top of those already in place, ensuring that calls that reach agents are using time more effectively, and providing more value to customers.</p> <p>Webscraping is a huge can of worms. Crawl4AI is a package that I happily stumbled across after trying to use other tools and resources for almost a month. I needed clean (enough) markdown files to give to a model so context could be retained and recalled from embeddings, and this managed to simplify the whole experience. The documentation made everything easy to implement, and it is free, which is honestly mind blowing. Customized agentic AI tools have so much potential to save time. Instead of needing all questions routed to someone who knows niche and specific documented information, LLM-based agents have blasted the ceiling wide open in terms of tools and repetitive workflows that can be automated now. I plan to implement some of these ideas during my upcoming internship with an insurance company based out of Southern Utah, and I anticipate each tool saving the company nearly 40 hours of customer support each week, allowing for additional earning potential, or just enough sleep at night.</p> <p>&lt;/div&gt;</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="seniorProject"/><category term="poster"/><summary type="html"><![CDATA[Final week of preparations; poster, presentation, conclusion]]></summary></entry><entry><title type="html">Week 10 - More RAG Research</title><link href="https://jtwiggs.github.io/blog/2025/Week10/" rel="alternate" type="text/html" title="Week 10 - More RAG Research"/><published>2025-03-26T14:28:26+00:00</published><updated>2025-03-26T14:28:26+00:00</updated><id>https://jtwiggs.github.io/blog/2025/Week10</id><content type="html" xml:base="https://jtwiggs.github.io/blog/2025/Week10/"><![CDATA[<h3 id="researching-rags">Researching RAG’s</h3> <p>This week wasn’t great so far as progress. The more I try and understand how RAG models work, the less easy it is for me to understand where I need to be headed. With only a month left before the R&amp;CW event, I don’t think I will be hitting the goals I had set initially when setting out for a senior project. Instead of air quality analysis, the project has leaned much more heavily into AI development. Instead of worrying about a predictive model to compare answers to, I am planning to either scrape data from a secondary source for the model to compare to, or just leave it at 1. Other classes are eating time away from this project, but I’m still planning to have a deliverable on time!</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="seniorProject"/><category term="n8n"/><summary type="html"><![CDATA[There is way more to this than I thought]]></summary></entry><entry><title type="html">Week 12 - Finalizing Everything</title><link href="https://jtwiggs.github.io/blog/2025/week12/" rel="alternate" type="text/html" title="Week 12 - Finalizing Everything"/><published>2025-03-26T14:28:26+00:00</published><updated>2025-03-26T14:28:26+00:00</updated><id>https://jtwiggs.github.io/blog/2025/week12</id><content type="html" xml:base="https://jtwiggs.github.io/blog/2025/week12/"><![CDATA[<h3 id="this-semester-is-wrapping-up---week-12">This Semester is Wrapping Up! - Week 12</h3> <p>Things are really getting down to the wire; I finally got a reliable way of extracting data from websites that is ingestible and instantaneously prepped for AI use. This has been done by way of the python library <a href="https://github.com/unclecode/crawl4ai">Crawl4AI</a>, and has made life quite a bit less stressful. At this point, I don’t think that there will be a secondary source of information, as RAG models are made to check markdown files, not necessarily call predictive models. We still have a couple weeks, so it might be possible, but that is no longer something I am aiming for. Hopefully by this time next week, there will be a model built in <a href="https://n8n.io/">n8n</a> and/or <a href="https://www.langchain.com/">Langchain</a> alongside a UI with <a href="https://streamlit.io/">Streamlit</a>.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="seniorProject"/><category term="n8n"/><summary type="html"><![CDATA[The week before the R&CW conference.]]></summary></entry><entry><title type="html">Week 11 - Crawl4AI</title><link href="https://jtwiggs.github.io/blog/2025/Week11/" rel="alternate" type="text/html" title="Week 11 - Crawl4AI"/><published>2025-03-19T21:01:00+00:00</published><updated>2025-03-19T21:01:00+00:00</updated><id>https://jtwiggs.github.io/blog/2025/Week11</id><content type="html" xml:base="https://jtwiggs.github.io/blog/2025/Week11/"><![CDATA[<p>This has been one of the best weeks of the semester so far as progress goes. I’ve found a much more specific tool to use for this project in the python library <a href="https://github.com/unclecode/crawl4ai">Crawl4AI</a>. Some of the key features include:</p> <ul> <li>asynchronous crawling</li> <li>Markdown formatting</li> <li>Content targeting</li> <li>much, much more…</li> </ul> <p>This package has extensive documentation and I would highly recommend checking it out. Moving on to the resource that lead to me finding Crawl4AI in the first place, <a href="https://www.youtube.com/@ColeMedin">Cole Medin’s channel</a> on YouTube. He not only has really insightful videos on agentic AI, but his project ideas are fascinating to follow along with. I’ve made reference to a couple of them in my research poster, and a link to the video that introduced me to his content is linked below. I feel like there is a great balance between technical explanations and beginner explanations. Additionally, <a href="https://www.youtube.com/@pixegami">pixelgami</a> is another channel that has great tutorials for creating RAG models in a simply explained way. I’ve also linked the video that was extremely helpful in this project below. I haven’t quite gotten the code working as of this post, so I will continue working on that and hopefully have a working model by next week. &lt;!– &lt;div class="row mt-3"&gt; &lt;div class="col-sm mt-3 mt-md-0"&gt;</p> <figure> <video src="/assets/video/pexels-engin-akyurt-6069112-960x540-30fps.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" autoplay="" controls=""/> </figure> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;/div&gt;
&lt;div class="col-sm mt-3 mt-md-0"&gt;
</code></pre></div></div> <figure> <video src="/assets/video/pexels-engin-akyurt-6069112-960x540-30fps.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" controls=""/> </figure> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;/div&gt;
</code></pre></div></div> <p>&lt;/div&gt;</p> <div class="caption"> A simple, elegant caption looks good between video rows, after each row, or doesn't have to be there at all. </div> <p>It does also support embedding videos from different sources. Here are some examples: –&gt;</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <iframe src="https://www.youtube.com/watch?v=U6LbW2IFUQw&amp;list=PLyrg3m7Ei-MqNM-au_lfjzTsuVVTTx0ke&amp;index=4&amp;pp=iAQB" class="img-fluid rounded z-depth-1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" width="auto" height="auto"/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <iframe src="https://www.youtube.com/watch?v=tcqEUSNCn8I&amp;t=731s" class="img-fluid rounded z-depth-1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" width="auto" height="auto"/> </figure> </div> </div> <div class="caption"> Here are the videos I found to be fairly insightful and helpful in building out the model and tools I needed. </div>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="videos"/><category term="webScraping"/><summary type="html"><![CDATA[Crawl4AI and other awesome resources]]></summary></entry><entry><title type="html">Week 8 - Career Fair</title><link href="https://jtwiggs.github.io/blog/2025/Week8/" rel="alternate" type="text/html" title="Week 8 - Career Fair"/><published>2025-03-05T14:28:26+00:00</published><updated>2025-03-05T14:28:26+00:00</updated><id>https://jtwiggs.github.io/blog/2025/Week8</id><content type="html" xml:base="https://jtwiggs.github.io/blog/2025/Week8/"><![CDATA[<h3 id="career-fair">Career Fair</h3> <p>There was a huge career fair this week, and while I am still feeling pretty under the weather, I felt that it would have been a huge waste not to go and talk to some potential employers about internship opportunities. Writing about this from a week later, I unfortunately missed some basic (but small) errors on my resume, but I had some printed, and got to hand out about 5 at the event. On top of that, I was better able to see what languages, skills, and directions that some of these companies were looking for. For all the applications and potential, I only got two interviews out of it. The biggest drawback of my resume is lacking work experience, and I need work experience to land a job… This is such a fun game.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="seniorProject"/><category term="portfolio"/><category term="resume"/><summary type="html"><![CDATA[Project was postponed]]></summary></entry><entry><title type="html">Week 9 - New Portfolio Site</title><link href="https://jtwiggs.github.io/blog/2025/Week9/" rel="alternate" type="text/html" title="Week 9 - New Portfolio Site"/><published>2025-03-05T14:28:26+00:00</published><updated>2025-03-05T14:28:26+00:00</updated><id>https://jtwiggs.github.io/blog/2025/Week9</id><content type="html" xml:base="https://jtwiggs.github.io/blog/2025/Week9/"><![CDATA[<h3 id="researching-rags">Researching RAG’s</h3> <p>This week I set about learning now to work with jekyll themes, and have chosen a new template to host my portfolio with. The Al-folio template is very easy to understand, and looks great to me. I spent most of my time this week getting a hand on what can and cannot be edited within each of the pages. Well… Everything can be customized, but I am not versed in web development so it felt like I was breaking code far more often than I was customizing it. By next week, I should have my about me page and resume page updated to reflect me instead of good old Albert Einstein.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="seniorProject"/><category term="portfolio"/><category term="gh-pages"/><summary type="html"><![CDATA[Al-folio is the way to go]]></summary></entry></feed>